{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":119450,"databundleVersionId":14288466,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training part","metadata":{}},{"cell_type":"code","source":"# importing nece libraries\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.metrics import roc_auc_score, accuracy_score, log_loss\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Importing data w start preprocessing\ntrain = pd.read_csv(\"/kaggle/input/pink-ai-breast-cancer-risk-prediction-challenge/train.csv\")\n\nX = train.drop(\"target\", axis=1)\ny = train[\"target\"]\n\nif \"ID\" in X.columns:\n    X_ids = X[\"ID\"]\n    X = X.drop(\"ID\", axis=1)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#feature engineering \nX = X.apply(pd.to_numeric, errors=\"coerce\")\n\nX[\"years_since_2005\"] = X[\"feature_0\"] - 2005  \nX[\"recent_screening\"] = (X[\"feature_0\"] >= 2015).astype(int) \n\nX[\"age_risk_interaction\"] = X[\"feature_2\"] * X[\"feature_4\"] \n\nX[\"high_risk_combo\"] = (\n    (X[\"feature_4\"] >= 2) & \n    (X[\"feature_7\"] == 1) &\n    (X[\"feature_10\"] == 1) \n).astype(int)\n\n\nX[\"severity_stage\"] = X[\"feature_5\"] + X[\"feature_8\"] \nX[\"advanced_case\"] = ((X[\"feature_5\"] >= 3) | (X[\"feature_8\"] >= 2)).astype(int)\n\nX[\"frequent_screener\"] = (X[\"feature_9\"] >= 3).astype(int) \nX[\"age_screening_match\"] = X[\"feature_2\"] * X[\"feature_9\"] \n\nX[\"high_risk_category\"] = (X[\"feature_1\"] >= 10).astype(int)\n\nprint(f\"Total features after engineering: {X.shape[1]}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#handling missing flags & cleaning\n\nmissing_flags = X.isna().astype(int).add_suffix(\"_isna\")\nX = pd.concat([X, missing_flags], axis=1)\n\n\nfor col in X.columns:\n    if X[col].dtype in [\"int64\",\"float64\"]:\n        X[col] = X[col].fillna(X[col].median())\n    else:\n        X[col] = X[col].astype(str).fillna(\"makanch\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ncategorical_columns = []\nfor col in ['feature_1', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_10', 'recent_screening', 'high_risk_combo', 'advanced_case', 'frequent_screener', 'high_risk_category']:\n    if col in X.columns:\n        categorical_columns.append(col)\n\nprint(f\"Converting these to categorical: {categorical_columns}\")\n\nfor col in categorical_columns:\n    if col in X.columns:\n        X[col] = X[col].astype('category')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# scaling\n\nscaler = StandardScaler()\nX[\"feature_0\"] = scaler.fit_transform(X[[\"feature_0\"]])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_mappings = {}\ncategorical_columns_final = X.select_dtypes(include=['category']).columns\nfor c in categorical_columns_final:\n    cat_mappings[c] = X[c].cat.categories.tolist()\n\nprint(f\"Final categorical features: {list(categorical_columns_final)}\")\n\nassert len(X) == len(y)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# splitting training & testing data\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.2, stratify=y, random_state=42\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model training\n\ndtrain = lgb.Dataset(X_train, label=y_train, categorical_feature=list(categorical_columns_final))\ndval = lgb.Dataset(X_val, label=y_val, categorical_feature=list(categorical_columns_final))\n\n\n#mod param\n\nparams = {\n    \"objective\": \"binary\",\n    \"boosting_type\": \"gbdt\",\n    \"metric\": [\"auc\", \"binary_logloss\"],\n    \"num_leaves\": 63,\n    \"learning_rate\": 0.02,\n    \"feature_fraction\": 0.7,\n    \"bagging_fraction\": 0.8,\n    \"bagging_freq\": 5,\n    \"min_child_samples\": 20,\n    \"seed\": 42,\n    \"verbose\": -1,\n}\n\nmodel = lgb.train(\n    params,\n    dtrain,\n    valid_sets=[dtrain, dval],\n    num_boost_round=5000,\n    callbacks=[\n        lgb.early_stopping(stopping_rounds=100),\n        lgb.log_evaluation(period=200)\n    ]\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prediction and accuracy check\n\ny_pred_proba = model.predict(X_val)\ny_pred_class = (y_pred_proba > 0.5).astype(int)\n\nprint(\"\\nValidation Metrics:\")\nprint(\"AUC:\", roc_auc_score(y_val, y_pred_proba))\nprint(\"Log Loss:\", log_loss(y_val, y_pred_proba))\nprint(\"Accuracy:\", accuracy_score(y_val, y_pred_class))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#important features plot\n\nlgb.plot_importance(model, max_num_features=15, importance_type=\"gain\", figsize=(8, 5))\nplt.title(\"Top 15 Feature Importances\")\nplt.show()\n\nprint(\"done\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Test data part","metadata":{}},{"cell_type":"code","source":"# importing the test dataset + applying same feature eng as the training set before\n\ntest = pd.read_csv(\"/kaggle/input/pink-ai-breast-cancer-risk-prediction-challenge/test.csv\")\ntest_ids = test[\"ID\"]\nX_test = test.drop(\"ID\", axis=1)\n\nX_test = X_test.apply(pd.to_numeric, errors=\"coerce\")\n\nX_test[\"years_since_2005\"] = X_test[\"feature_0\"] - 2005\nX_test[\"recent_screening\"] = (X_test[\"feature_0\"] >= 2015).astype(int)\n\nX_test[\"age_risk_interaction\"] = X_test[\"feature_2\"] * X_test[\"feature_4\"]\n\nX_test[\"high_risk_combo\"] = (\n    (X_test[\"feature_4\"] >= 2) & \n    (X_test[\"feature_7\"] == 1) & \n    (X_test[\"feature_10\"] == 1)\n).astype(int)\n\nX_test[\"severity_stage\"] = X_test[\"feature_5\"] + X_test[\"feature_8\"]\nX_test[\"advanced_case\"] = ((X_test[\"feature_5\"] >= 3) | (X_test[\"feature_8\"] >= 2)).astype(int)\n\nX_test[\"frequent_screener\"] = (X_test[\"feature_9\"] >= 3).astype(int)\nX_test[\"age_screening_match\"] = X_test[\"feature_2\"] * X_test[\"feature_9\"]\n\nX_test[\"high_risk_category\"] = (X_test[\"feature_1\"] >= 10).astype(int)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_flags_test = X_test.isna().astype(int).add_suffix(\"_isna\")\nX_test = pd.concat([X_test, missing_flags_test], axis=1)\n\nfor col in X_test.columns:\n    if X_test[col].dtype in [\"int64\",\"float64\"]:\n        X_test[col] = X_test[col].fillna(X_test[col].median())\n    else:\n        X_test[col] = X_test[col].astype(str).fillna(\"makanch\")\n\nfor c in cat_mappings:\n    if c in X_test.columns:\n        X_test[c] = X_test[c].astype(str)\n        unseen_categories = set(X_test[c]) - set(cat_mappings[c])\n        if unseen_categories:\n            print(f\"Warning: Unseen categories in {c}: {unseen_categories}\")\n            X_test.loc[X_test[c].isin(unseen_categories), c] = \"makanch\"\n        X_test[c] = pd.Categorical(X_test[c], categories=cat_mappings[c])\n\nX_test[\"feature_0\"] = scaler.transform(X_test[[\"feature_0\"]])\n\nmissing_cols = set(X.columns) - set(X_test.columns)\nif missing_cols:\n    print(f\"Adding missing columns: {missing_cols}\")\n    for col in missing_cols:\n        X_test[col] = 0\n\nX_test = X_test[X.columns]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# prediction \n\ntest_pred_proba = model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#submission\n\nsubmission = pd.DataFrame({\n    \"ID\": test_ids,\n    \"target\": test_pred_proba\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"saved\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-01T16:57:28.029246Z","iopub.execute_input":"2025-11-01T16:57:28.030435Z","iopub.status.idle":"2025-11-01T16:58:27.988608Z","shell.execute_reply.started":"2025-11-01T16:57:28.030335Z","shell.execute_reply":"2025-11-01T16:58:27.987524Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater_equal\n  return op(a, b)\n","output_type":"stream"},{"name":"stdout","text":"Warning: Unseen categories in feature_1: {'8.0', '4.0', '1.0', '12.0', '11.0', '13.0', '5.0', '2.0', '10.0', '3.0', '6.0', '7.0'}\nWarning: Unseen categories in feature_4: {'1.0', '2.0', '0.0'}\nWarning: Unseen categories in feature_5: {'4.0', '1.0', '0.0', '2.0', '3.0'}\nWarning: Unseen categories in feature_6: {'3.0', '4.0', '1.0', '2.0'}\nWarning: Unseen categories in feature_7: {'1.0', '0.0'}\nWarning: Unseen categories in feature_8: {'3.0', '1.0', '2.0'}\nWarning: Unseen categories in feature_10: {'1.0', '0.0'}\nWarning: Unseen categories in recent_screening: {'1', '0'}\nWarning: Unseen categories in high_risk_combo: {'1', '0'}\nWarning: Unseen categories in advanced_case: {'1', '0'}\nWarning: Unseen categories in frequent_screener: {'1', '0'}\nWarning: Unseen categories in high_risk_category: {'1', '0'}\nSubmission file created successfully!\nTest predictions shape: (297860,)\n","output_type":"stream"}],"execution_count":2}]}